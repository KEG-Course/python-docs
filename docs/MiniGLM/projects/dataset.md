# 数据集和预处理介绍

## 预训练数据集

预训练的目的是为了让模型能够“记住”数据中的内容，所以一般选用互联网、知识库或者书籍数据进行训练。预训练数据的形式一般为可阅读的文本、文章等。

#### 数据集介绍：

​	考虑到模型的大小，本次实验我们旨在训练一个特定领域的小模型——中文wiki百科数据集。我们选取了其中一个子集作为训练集进行预训练，大家可以自行选取部分进行使用，并在进行演示和实验报告中说明。我们的测试集出题范围将被限制在这个子集：

https://cloud.tsinghua.edu.cn/d/d6f9966d6b684b05a516/

如果需要使用更多中文wiki预训练语料，可以从以下来源下载：

https://drive.google.com/file/d/1EdHUZIDpgcBoSqbjlfNKJ3b1t0XIUjbt/view?usp=sharing

其中，每条数据的内容都是json文件，这是一个例子：

```
{"id": "53", "url": "https://zh.wikipedia.org/wiki?curid=53", "title": "经济学", "text": "经济学\n\n经济学是一门对产品和服务的生产、分配以及消费进行研究的社会科学。西方语言中的“经济学”一词源于古希腊的。\n\n经济学注重的是研究经济行为者在一个经济体系下的行为，以及他们彼此之间的互动。在现代，经济学的教材通常将这门领域的研究分为总体经济学和个体经济学。微观经济学检视一个社会里基本层次的行为，包括个体的行为者（例如个人、公司、买家或卖家）以及与市场的互动。而宏观经济学则分析整个经济体和其议题，包括失业、通货膨胀、经济成长、财政和货币政策等。..."}
```

你也可以自由选用其他数据集作为预训练数据集，并且在演示和实验报告中说明。

#### 数据处理流程

数据处理流程的主要目标是将原始文本数据编码为模型可以理解的标记序列，并将其分成训练集和验证集以供后续的模型训练和评估使用。在本次作业中，我们使用 `tiktoken` 库来处理文本数据。最终，编码后的数据以二进制格式保存在文件中，以供学习模型使用。主要包括以下流程：

1. 获取文本编码器
      - 使用 `tiktoken.get_encoding("gpt2")` 获取用于编码文本的编码器。在此示例中，选择了 GPT-2 模型的编码器。
2. 文本编码
      - 使用获取的编码器对读取的文本数据进行编码。`enc.encode_ordinary(data)` 将文本转换为标记序列.
3. 训练集和验证集划分
      - 将文本数据划分为训练集和验证集（可选）。这种划分方式有助于模型的验证和性能评估。
4. 数据保存
      - 使用 NumPy 将编码后的文本数据保存为二进制文件。训练集和验证集分别保存在名为 `train.bin` 和 `val.bin` 的文件中。这样的保存方式可使数据在后续训练时更加高效地加载。

## 微调数据集构建

微调阶段是未来让模型能够利用预训练中“学习”到的知识和内容，来进行问答和对话。微调数据集的形式一般为问答对的形式：

```
{
	"question": "微观经济学和宏观经济学分别研究哪些内容？",
	"answer": "微观经济学检视一个社会里基本层次的行为，包括个体的行为者（例如个人、公司、买家或卖家）以及与市场的互动；宏观经济学则分析整个经济体和其议题，包括失业、通货膨胀、经济成长、财政和货币政策等。"
}
```

#### 数据集介绍

本次实验提供20条样例微调数据，作为参考数据集。微调数据也需要经历类似预训练的数据处理流程：

1. 利用文本编码器对`question`和`answer`分别编码，同时进行适当的拼接。
2. 通过适当标识区分`question`和`answer`.
3. 训练集和验证集划分。
4. 处理不同长度的数据

除提供的微调数据集之外，强烈建议大家通过多种方式构建更多额外的数据用于微调，包括。获取微调数据的途径可以包括：

1. 自己和同学一起手写微调数据（问题和答案）
2. 利用现有 AI 模型进行辅助数据生成。

也可以观察不同数据量进行微调的模型的效果。
