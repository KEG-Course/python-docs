## 聊天机器人竞技场（Chatbot Arena）

本部分的主要目标是将你在实验中训练的模型与其他同学的模型运用于一个实时的聊天竞技场中，你需要找到2至3个同学进行组队。

## 竞技场界面

`每个同学`都需要独立实现一个竞技场界面，用来展示不同模型输出的结果方便进行对比。

实现步骤：
1. 聊天界面开发：开发一个简单的前端界面，该界面可以允许用户输入问题，并实时展示两个模型的回复内容。推荐基于已实现的前端进行修改及开发。
2. 模型选择：需要能选择你自己的模型以及其他同学的模型中任两者作为竞技对象。
3. 流式输出：对于模型输出内容，前端要实现打字机效果进行前端展示。

## 模型API部署

为了使你的模型能在自己及其他同学的聊天机器人竞技场中运行，你需要将你的聊天机器人模型部署为一个可局域网访问的API。

实现步骤：
1. 封装模型：将你训练的模型封装到一个API中，此API接受来自前端的请求（建议包含一些常见模型推理参数设置，如`temperature`、`top-p`、`max-length`等），并返回模型的输出。
2. 本地测试：在部署之前在本地测试API，确保它能够接受请求并正确返回结果。
3. 连调测试：与同组同学进行，确保网络访问正常。

## 服务器资源

为了让大家能够顺利完成作业。避免硬件资源限制，我们会为大家提供服务器资源供大家使用。

- 每台服务器有8张24G的显卡。每次程序运行大约需要10G显存，理论上一张显卡最多可以跑2个程序

- 平均11人使用一台服务器。建议尽量平均使用资源

###服务器的使用

要使用服务器进行开发，需要通过 ssh 连接到服务器上，使用命令行进行操作

- 使用 ssh 连接服务器，所有机器通过端口`12272`访问

  ```
  mac：ssh <账号>@ip -p 12272
  
  windows：使用 xshell 等支持 ssh 的软件
  ```

- 激活 conda 环境。我们在服务器上为大家配置了共享 conda 环境，登入服务器后环境会自动激活。由于环境为服务器上所有同学共享，请大家不要随意通过 pip 安装 package。

- 需要的代码和数据可以放在个人目录下进行 `/home/p y<学号>`，不同成员目录禁止相互访问。

- 服务器和本地之间的文件传输可以用`scp`实现。windows 下可以用`xftp`。

- 可以通过 `CUDA_VISIBLE_DEVICES=x` 来约束使用哪一张显卡。例如：`CUDA_VISIBLE_DEVICES=4 python main.py`为使用4号显卡来运行程序

- 可以利用`nvidia-smi`查看GPU使用情况

- 账号通过网络学堂作业下发
