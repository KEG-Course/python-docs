# 爬虫

## 数据爬取

* 从任意新闻网站的科技板块中选取，爬取其中的信息。
    * 例如：腾讯新闻、新浪新闻、网易新闻、央视新闻等。
* 爬取信息：
    * 标题
    * 作者基本信息：作者ID、作者头像、粉丝数量等（根据网站显示内容爬取）
    * 基本信息：创建时间、阅读数量、点赞收藏数量等（根据网站显示内容爬取）
    * 正文：全文文本以及其中的图片与代码
    * 网页URL
    * 其他可能需要的信息

## 相关要求

* 爬取的新闻数量不少于5000。
* 爬取的新闻正文的文本格式（小标题、加粗、颜色等）不作要求，保留与否均可。
* 新闻中除图片外的其他多媒体（音视频等）不作要求。

## 注意事项

* 注意网站可能存在的反爬机制，并调整爬虫策略
    * 不要野蛮抓取、两次爬取中间建议停顿一定时间（建议两次爬取之间至少设置1s间隔）
    * 设Headers，动态User-Agent头
    * 换Cookie
    * 换IP
    * （有条件）代理池
* Tip：建议在本地存储已爬到的页面URL和HTML文件，防止爬虫程序意外崩溃或被反爬激活后损失数据，并能有效地继续爬取。
* 如被反爬机制封禁，允许保留已有数据，换其他网站继续爬取。
* 不限制爬虫所使用的Python第三方库(bs4、Scrapy等)
